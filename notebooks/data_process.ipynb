{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../raw_data/'\n",
    "processed_data_path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = pd.read_csv(raw_data_path + 'WHO-COVID-19-global-data.csv')[['Country_code', 'Country']].drop_duplicates().set_index('Country_code')\n",
    "country_list.to_csv(processed_data_path + 'countries_list.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_population = pd.read_csv(raw_data_path + 'countries_population.csv')\n",
    "countries_population['pop2020'] = countries_population['pop2020'] * 1000\n",
    "countries_population[['cca2', 'pop2020']].rename(columns={'cca2':'Country_code'}).to_csv(processed_data_path + 'countries_population.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDPpC = pd.read_csv(raw_data_path + 'GDPPerCapita.csv')[['Country', 'GDP Per Capita']]\n",
    "country_list.join(GDPpC.set_index('Country'), on='Country', how='inner').drop(columns='Country').to_csv(processed_data_path + 'GDPPerCapita.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_active = pd.read_csv(raw_data_path + 'k_average/kaverageall_locationsPLOSComp.csv')\n",
    "k_active.replace('Bolivia (Plurinational State of','Bolivia (Plurinational State of)',inplace=True)\n",
    "k_active.replace('United Kingdom of Great Britain','The United Kingdom',inplace=True)\n",
    "k_active.replace('Turkey', 'Türkiye', inplace=True)\n",
    "k_active.to_csv(processed_data_path + 'k_average/k_active.txt', sep=',', index=False)\n",
    "\n",
    "k_passive = pd.read_csv(raw_data_path + 'k_average/kaveragehomePLOSComp.csv')\n",
    "k_passive.replace('Bolivia (Plurinational State of','Bolivia (Plurinational State of)',inplace=True)\n",
    "k_passive.replace('United Kingdom of Great Britain','The United Kingdom',inplace=True)\n",
    "k_passive.replace('Turkey', 'Türkiye', inplace=True)\n",
    "k_passive.to_csv(processed_data_path + 'k_average/k_passive.txt', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "households = pd.read_csv(raw_data_path + 'households.csv')\n",
    "households['Reference date'] = pd.to_datetime(households['Reference date'], format='%d/%m/%Y')\n",
    "\n",
    "# #take latest date from each country\n",
    "households = households.sort_values(['Country','Reference date']).groupby('Country').tail(1).set_index('Country')\n",
    "\n",
    "households = households.reset_index()\n",
    "households = households.replace('United Kingdom', 'The United Kingdom')\n",
    "households = households.replace('Turkey', 'Türkiye')\n",
    "households = households.set_index('Country')\n",
    "\n",
    "households = households.merge(country_list, left_index=True, right_on='Country').drop(columns='Country')#.to_csv('data/households.txt', index=False)\n",
    "\n",
    "households = households[['household']].dropna()\n",
    "\n",
    "households['household'].to_csv(processed_data_path + 'households.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Country_code in [\"AR\", \"AT\", \"BD\", \"BE\", \"BO\", \"BG\", \"CA\", \"CL\", \"CO\",\n",
    "                \"EG\", \"FR\", \"GR\", \"DE\", \"GT\", \"HN\", \"HU\", \"ID\", \"IQ\", \"IE\",\n",
    "                \"IL\", \"IT\", \"KW\", \"LU\", \"MY\", \"MX\", \"MA\", \"NG\", \"PK\", \"PA\",\n",
    "                \"PH\", \"PL\", \"PT\", \"RO\", \"RU\", \"SA\", \"ZA\", \"ES\", \"CH\", \"TR\",\n",
    "                \"US\", \"GB\", \"UA\"]:\n",
    "\n",
    "    dead_obs = pd.read_csv(raw_data_path + 'WHO-COVID-19-global-data.csv')\n",
    "    dead_obs = dead_obs[dead_obs['Country_code'] == Country_code]\n",
    "    dead_obs['Date_reported'] = pd.to_datetime(dead_obs['Date_reported'])\n",
    "    dead_obs = dead_obs[['Date_reported', 'New_deaths']].rename(columns={'Date_reported':'date', 'New_deaths':'dead'}).set_index('date')\n",
    "    dead_obs['dead'] = dead_obs['dead'].rolling(7,center=True).mean()\n",
    "\n",
    "\n",
    "    mobility = pd.read_csv(raw_data_path + 'Region_Mobility_Report_CSVs/2020_' + Country_code + '_Region_Mobility_Report.csv')\n",
    "\n",
    "    mobility_kind = 'retail_and_recreation_percent_change_from_baseline'\n",
    "\n",
    "    mobility = mobility[mobility[['sub_region_1', 'sub_region_2', 'metro_area', 'iso_3166_2_code','census_fips_code']].isna().all(axis=1)][['date', mobility_kind]].rename(columns={mobility_kind:'mobility'})\n",
    "    mobility = mobility.set_index('date')\n",
    "    mobility.index = pd.to_datetime(mobility.index)\n",
    "    mobility['mobility'] = 1 + mobility['mobility']/100\n",
    "    mobility['mobility'] = mobility['mobility'].rolling(7,center=True).mean()\n",
    "    mobility[mobility.isna()] = 1\n",
    "    mobility[mobility['mobility'] > 1] = 1\n",
    "\n",
    "    date_i = '2020-02-01'\n",
    "    date_f = '2020-05-20'\n",
    "\n",
    "    dead_obs = dead_obs[(dead_obs.index >= date_i) & (dead_obs.index <= date_f)]\n",
    "    mobility = mobility[(mobility.index >= date_i) & (mobility.index <= date_f)]\n",
    "\n",
    "    extra_days = ((mobility.index[0] - pd.to_datetime(date_i)).days)\n",
    "    original_date = mobility.index[0]\n",
    "\n",
    "    date = pd.to_datetime(original_date)\n",
    "    for i in range(extra_days):\n",
    "        date = date - pd.Timedelta(days=1)\n",
    "        mobility.loc[date] = 1.0\n",
    "    mobility = mobility.sort_index()\n",
    "\n",
    "    dead_obs.to_csv(f'{processed_data_path}dead/dead_{Country_code}.txt', sep='\\t', header=None)\n",
    "    mobility.to_csv(f'{processed_data_path}mobility/mobility_{Country_code}.txt', sep='\\t', header=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobility residential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Country_code in [\"AR\", \"AT\", \"BD\", \"BE\", \"BO\", \"BG\", \"CA\", \"CL\", \"CO\",\n",
    "                \"EG\", \"FR\", \"GR\", \"DE\", \"GT\", \"HN\", \"HU\", \"ID\", \"IQ\", \"IE\",\n",
    "                \"IL\", \"IT\", \"KW\", \"LU\", \"MY\", \"MX\", \"MA\", \"NG\", \"PK\", \"PA\",\n",
    "                \"PH\", \"PL\", \"PT\", \"RO\", \"RU\", \"SA\", \"ZA\", \"ES\", \"CH\", \"TR\",\n",
    "                \"US\", \"GB\", \"UA\"]:\n",
    "\n",
    "    mobility = pd.read_csv(raw_data_path + 'Region_Mobility_Report_CSVs/2020_' + Country_code + '_Region_Mobility_Report.csv')\n",
    "\n",
    "    # mobility_kind = 'retail_and_recreation_percent_change_from_baseline'\n",
    "    mobility_kind = 'residential_percent_change_from_baseline'\n",
    "\n",
    "    mobility = mobility[mobility[['sub_region_1', 'sub_region_2', 'metro_area', 'iso_3166_2_code','census_fips_code']].isna().all(axis=1)][['date', mobility_kind]].rename(columns={mobility_kind:'mobility'})\n",
    "    mobility = mobility.set_index('date')\n",
    "    mobility.index = pd.to_datetime(mobility.index)\n",
    "    mobility['mobility'] = 1 + mobility['mobility']/100\n",
    "    mobility['mobility'] = mobility['mobility'].rolling(7,center=True).mean()\n",
    "    mobility[mobility.isna()] = 1\n",
    "\n",
    "    date_i = '2020-02-01'\n",
    "    date_f = '2020-05-20'\n",
    "\n",
    "    mobility = mobility[(mobility.index >= date_i) & (mobility.index <= date_f)]\n",
    "\n",
    "    extra_days = ((mobility.index[0] - pd.to_datetime(date_i)).days)\n",
    "    original_date = mobility.index[0]\n",
    "\n",
    "    date = pd.to_datetime(original_date)\n",
    "    for i in range(extra_days):\n",
    "        date = date - pd.Timedelta(days=1)\n",
    "        mobility.loc[date] = 1.0\n",
    "    mobility = mobility.sort_index()\n",
    "\n",
    "    mobility.to_csv(f'{processed_data_path}mobility_residential/mobility_{Country_code}.txt', sep='\\t', header=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobility workplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Country_code in [\"AR\", \"AT\", \"BD\", \"BE\", \"BO\", \"BG\", \"CA\", \"CL\", \"CO\",\n",
    "                \"EG\", \"FR\", \"GR\", \"DE\", \"GT\", \"HN\", \"HU\", \"ID\", \"IQ\", \"IE\",\n",
    "                \"IL\", \"IT\", \"KW\", \"LU\", \"MY\", \"MX\", \"MA\", \"NG\", \"PK\", \"PA\",\n",
    "                \"PH\", \"PL\", \"PT\", \"RO\", \"RU\", \"SA\", \"ZA\", \"ES\", \"CH\", \"TR\",\n",
    "                \"US\", \"GB\", \"UA\"]:\n",
    "\n",
    "    mobility = pd.read_csv(raw_data_path + 'Region_Mobility_Report_CSVs/2020_' + Country_code + '_Region_Mobility_Report.csv')\n",
    "\n",
    "    # mobility_kind = 'retail_and_recreation_percent_change_from_baseline'\n",
    "    mobility_kind = 'workplaces_percent_change_from_baseline'\n",
    "\n",
    "    mobility = mobility[mobility[['sub_region_1', 'sub_region_2', 'metro_area', 'iso_3166_2_code','census_fips_code']].isna().all(axis=1)][['date', mobility_kind]].rename(columns={mobility_kind:'mobility'})\n",
    "    mobility = mobility.set_index('date')\n",
    "    mobility.index = pd.to_datetime(mobility.index)\n",
    "    mobility['mobility'] = 1 + mobility['mobility']/100\n",
    "    mobility['mobility'] = mobility['mobility'].rolling(7,center=True).mean()\n",
    "    mobility[mobility.isna()] = 1\n",
    "    mobility[mobility['mobility'] > 1] = 1\n",
    "\n",
    "    date_i = '2020-02-01'\n",
    "    date_f = '2020-05-20'\n",
    "\n",
    "    mobility = mobility[(mobility.index >= date_i) & (mobility.index <= date_f)]\n",
    "\n",
    "    extra_days = ((mobility.index[0] - pd.to_datetime(date_i)).days)\n",
    "    original_date = mobility.index[0]\n",
    "\n",
    "    date = pd.to_datetime(original_date)\n",
    "    for i in range(extra_days):\n",
    "        date = date - pd.Timedelta(days=1)\n",
    "        mobility.loc[date] = 1.0\n",
    "    mobility = mobility.sort_index()\n",
    "\n",
    "    mobility.to_csv(f'{processed_data_path}mobility_workplace/mobility_{Country_code}.txt', sep='\\t', header=None)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
